{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f807bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔢 1. MAE – Mean Absolute Error\n",
    "# What it means:\n",
    "# How much your predictions are off from the actual value — on average.\n",
    "\n",
    "# Simple example:\n",
    "\n",
    "# Real: ₹100, ₹150, ₹200\n",
    "\n",
    "# Predicted: ₹110, ₹140, ₹180\n",
    "\n",
    "# Errors: 10, 10, 20 → Take average = (10+10+20)/3 = 13.33\n",
    "\n",
    "# ✅ Easy to understand — it tells you the average error.\n",
    "# ❌ Doesn't care if you're sometimes very wrong (no squaring)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15461273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧮 2. MSE – Mean Squared Error\n",
    "# What it means:\n",
    "# Like MAE, but you square the errors before averaging.\n",
    "\n",
    "# Why square?\n",
    "# To punish bigger mistakes more.\n",
    "\n",
    "# Errors: 10, 10, 20\n",
    "\n",
    "# Squared: 100, 100, 400\n",
    "\n",
    "# MSE = (100 + 100 + 400) / 3 = 200\n",
    "\n",
    "# ✅ Useful when you want to penalize big errors a lot.\n",
    "# ❌ Bigger numbers, harder to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bcef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📏 3. RMSE – Root Mean Squared Error\n",
    "# What it means:\n",
    "# Just the square root of MSE.\n",
    "\n",
    "# Why? Because MSE is big and not in original units. RMSE brings it back to original unit (like ₹, °C, etc.)\n",
    "\n",
    "# MSE = 200\n",
    "\n",
    "# RMSE = √200 ≈ 14.14\n",
    "\n",
    "# ✅ Easy to compare with real values.\n",
    "# ✅ Still punishes big errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60521b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📈 4. R² Score (R-Squared)\n",
    "# What it means:\n",
    "# How much of the variation in real values your model can explain.\n",
    "\n",
    "# It’s like a score out of 1 (or 100%).\n",
    "\n",
    "# R² = 1 → Perfect model\n",
    "\n",
    "# R² = 0 → Model is as dumb as just predicting average\n",
    "\n",
    "# R² < 0 → Model is worse than guessing 😅\n",
    "\n",
    "# ✅ Very useful to know how good the model is overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dab88c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❗ 5. Absolute (abs)\n",
    "# What it means:\n",
    "# It simply means remove the negative sign.\n",
    "\n",
    "# Like:\n",
    "\n",
    "# abs(-5) = 5\n",
    "\n",
    "# abs(3) = 3\n",
    "\n",
    "# This is used in MAE, so the error is always positive."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
